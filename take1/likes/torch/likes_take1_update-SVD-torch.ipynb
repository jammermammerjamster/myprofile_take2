{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e030b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]= \"expandable_segments:True\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "# torch.cuda.is_available = lambda : False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca107524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    }
   ],
   "source": [
    "import readline\n",
    "import scipy.sparse\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from keras_core.models import Sequential\n",
    "from keras_core.layers import Input, Dense, Dropout, Activation\n",
    "from keras_core.optimizers import RMSprop, Adam, Nadam, Adamax\n",
    "from keras_core.models import model_from_json\n",
    "# import sklearn.external.joblib as extjoblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f39952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'LIKES' from the training dataset and process\n",
    "###############\n",
    "likes = pd.read_csv(\"/home/jamster/old-repos/ml2018-projectDATA/tcss555/training/relation/relation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1ca714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# likes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40fb3829-8683-414f-a5df-df1fb0b8f61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'userid', 'like_id'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a35ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extact individual columns and convert to lists\n",
    "likesUIDs = likes['userid'].values\n",
    "likesLIDs = likes['like_id'].values\n",
    "lsLikesUIDs = likesUIDs.tolist()\n",
    "lsLikesLIDs = likesLIDs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50585e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to sets\n",
    "setLikesUIDs = set(lsLikesUIDs)\n",
    "setLikesLIDs = set(lsLikesLIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b2c7c99-2539-4af6-821e-e37826e91fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to list of unique items\n",
    "unqLikesUIDs = (list(setLikesUIDs))\n",
    "unqLikesLIDs = (list(setLikesLIDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259d4348-53cc-4c78-9313-e0e8aad4231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all User IDs (UIDs) paried with the Like IDs (LIDs) of the \n",
    "#   posts the user has liked\n",
    "allLikesLS = [lsLikesUIDs, [str(x) for x in lsLikesLIDs]]\n",
    "allLikesLS = list(map(list, zip(*allLikesLS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b9641e-6c2f-4990-b970-939ccfd49165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of UID and LID pairs into a dictionary indexed by UIDs\n",
    "aDictLikes2 = {}\n",
    "for aUID in unqLikesUIDs:\n",
    "\taDictLikes2[aUID]=[]\n",
    "\n",
    "for row in allLikesLS:\n",
    "\taDictLikes2[row[0]].append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0284345a-7859-4c5f-9a22-0dc130d6e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into a dictionary (by UIDs) of dictionaries (by LIDs)\n",
    "combDICT = {}\n",
    "for uid in unqLikesUIDs:\n",
    "\ttmpDICT={}\n",
    "\ttmpLS = aDictLikes2[uid]\n",
    "\tfor row in tmpLS:\n",
    "\t\ttmpDICT[str(row)]=1\n",
    "\tcombDICT[uid]=tmpDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ed975d-2b77-4c87-b31f-e6b8d0fe5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'combDICT' into a list of dictionaries (of LIDs)\n",
    "tryTHIS=[]\n",
    "for uid in unqLikesUIDs:\n",
    "\ttryTHIS.append(combDICT[uid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10716796-702c-4867-96d0-f48345accb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the list of dictionaries in 'tryTHIS' to get the UID/LID matrix \n",
    "#   for the training data\n",
    "v = DictVectorizer()\n",
    "likesMAT=v.fit_transform(tryTHIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a7ee0d6-6faf-4860-8e32-8e16129df67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear unused variable to free memory\n",
    "del globals()['likes']\n",
    "del globals()['likesUIDs']\n",
    "del globals()['likesLIDs']\n",
    "del globals()['lsLikesUIDs']\n",
    "del globals()['lsLikesLIDs']\n",
    "del globals()['setLikesUIDs']\n",
    "del globals()['setLikesLIDs']\n",
    "del globals()['allLikesLS']\n",
    "del globals()['aDictLikes2']\n",
    "del globals()['aUID']\n",
    "del globals()['row']\n",
    "del globals()['combDICT']\n",
    "del globals()['uid']\n",
    "del globals()['tmpDICT']\n",
    "del globals()['tmpLS']\n",
    "del globals()['tryTHIS']\n",
    "del globals()['v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d7d954e-25b4-4a41-b935-810db7854b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the profiles from the training dataset\n",
    "###############\n",
    "profilesDF=pd.read_csv(\"/home/jamster/old-repos/ml2018-projectDATA/tcss555/training/profile/profile.csv\")\n",
    "\n",
    "# profilesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d84afc-d6cc-45bc-b4f6-8129ca7f657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'userid', 'age', 'gender', 'ope', 'con', 'ext', 'agr',\n",
       "       'neu'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profilesDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6e7b349-e9fe-4af2-baba-e1c11a0ac68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the values of the relevant columns and convert them to a list\n",
    "profiles=profilesDF[['userid', 'age', 'gender', 'ope', 'con', 'ext', 'agr', 'neu']].values.copy()\n",
    "profilesLSo=profiles.tolist().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "635f8d9d-b614-45d9-9267-c26e9b80a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the ages\n",
    "profilesLS=[]\n",
    "for row in profilesLSo:\n",
    "\ttmpLS=row\n",
    "\ttmpAGE=row[1]\n",
    "\n",
    "\tif tmpAGE < 25:\n",
    "\t\ttmpLS[1]=1\n",
    "\telif tmpAGE < 35:\n",
    "\t\ttmpLS[1]=2\n",
    "\telif tmpAGE < 50:\n",
    "\t\ttmpLS[1]=3\n",
    "\telse:\n",
    "\t\ttmpLS[1]=4\n",
    "\n",
    "\tprofilesLS.append(tmpLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f8bbb0a-a393-410b-b09e-986caa68dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the profiles data with the indexing of the likes data\n",
    "profsTOlikes=[]\n",
    "for i in range(len(profilesLS)):\n",
    "\tprofsTOlikes.append([])\n",
    "\n",
    "for row in profilesLS:\n",
    "\ttmpIND = unqLikesUIDs.index(row[0])\n",
    "\tprofsTOlikes[tmpIND]=row\n",
    "\n",
    "profsTOlikes1=list(map(list, zip(*profsTOlikes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b17e2d38-6299-4511-9c2f-abef47286b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Data for AGEs\n",
    "agesARRo=np.array(profsTOlikes1[1])\n",
    "agesARRo=agesARRo.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68b035a8-ddb0-4a37-b139-4a547bc02696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data for AGEs to binary vectors\n",
    "agesARR = []\n",
    "for row in agesARRo:\n",
    "\tif row==1:\n",
    "\t\tagesARR.append([1,0,0,0])\n",
    "\telif row==2:\n",
    "\t\tagesARR.append([0,1,0,0])\n",
    "\telif row==3:\n",
    "\t\tagesARR.append([0,0,1,0])\n",
    "\telse:\n",
    "\t\tagesARR.append([0,0,0,1])\n",
    "\n",
    "agesARR=np.array(agesARR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "592ebe3a-dfcf-4fd2-b6b6-9fbe4b73831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear MORE unused variable to free memory\n",
    "del globals()['unqLikesUIDs']\n",
    "del globals()['unqLikesLIDs']\n",
    "del globals()['profilesDF']\n",
    "del globals()['profiles']\n",
    "del globals()['profilesLSo']\n",
    "del globals()['profilesLS']\n",
    "del globals()['row']\n",
    "del globals()['tmpLS']\n",
    "del globals()['tmpAGE']\n",
    "del globals()['profsTOlikes']\n",
    "del globals()['i']\n",
    "del globals()['tmpIND']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2aff8-db31-4f73-bc88-059266995815",
   "metadata": {},
   "source": [
    "Need to pickle the numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a0ccbcc-dfa4-477f-816e-c25bf7d79482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92c6d472-c049-4186-94f4-2501c965008e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50b9d791-214b-4125-95bb-851a68845833",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff2ae18d-2e0b-4720-aa0b-ab2c3d82608e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# torch.cuda.set_device(0)\n",
    "# torch.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d4e4d4e-463d-457d-992f-eea9cdd30d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_likesMAT, test_likesMAT, train_agesARR, test_agesARR = train_test_split(likesMAT, agesARR, test_size=0.05, random_state=42)\n",
    "# train_likesMAT, test_likesMAT, train_agesARR, test_agesARR = train_test_split(likesMAT, agesARR, test_size=0.85, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d1a143f-53ec-4af6-8e7b-63c059a105d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from scipy import linalg, sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b1a097d-9609-451c-8319-53634e1e20d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9025, 9025)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_likesMAT_1 = np.dot(train_likesMAT, train_likesMAT.T)\n",
    "sq_likesMAT_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b33ff30-1001-49f8-9f1f-7d5a8d115b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "tensor_sq_likesMAT_1 = torch.Tensor(sq_likesMAT_1.todense()) \\\n",
    "                            .to(torch.float) \\\n",
    "                            .cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c5743fd-1336-4875-8add-7d610f20bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_sq_likesMAT_1_evals = torch.linalg.eig(tensor_sq_likesMAT_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4107be0-dade-482b-b293-03ade21330db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.433316e+04 2.279608e+04 8.965205e+03 ... 2.000000e+00 4.000000e+00\n",
      " 1.000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_98773/3888341673.py:1: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:305.)\n",
      "  sq_likesMAT_1_evals = tensor_sq_likesMAT_1_evals.eigenvalues.to(torch.float32).cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "sq_likesMAT_1_evals = tensor_sq_likesMAT_1_evals.eigenvalues.to(torch.float32).cpu().numpy()\n",
    "\n",
    "del tensor_sq_likesMAT_1_evals\n",
    "del tensor_sq_likesMAT_1\n",
    "\n",
    "print(sq_likesMAT_1_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "614f3927-b8d2-43d8-b123-fb8bc3c49145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9693528e-01 4.2805117e-01 4.5301065e-01 ... 8.9652051e+03 2.2796080e+04\n",
      " 6.4333160e+04]\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(sq_likesMAT_1_evals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bd4bcda-8ad7-47ae-9602-188c9bd32f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1424.2222  1436.4185  1437.7374  1440.2511  1441.6886  1448.3381\n",
      "  1454.7435  1464.5554  1469.1974  1474.5692  1481.4847  1487.3687\n",
      "  1493.6383  1499.3894  1508.558   1514.324   1521.7627  1529.1177\n",
      "  1537.638   1544.0542  1546.006   1561.2601  1575.5616  1578.5449\n",
      "  1580.8926  1584.5984  1593.2631  1598.5974  1613.5791  1614.3868\n",
      "  1623.559   1642.423   1648.188   1653.9132  1671.477   1677.528\n",
      "  1683.7715  1688.0109  1699.5115  1708.4006  1715.9788  1721.6787\n",
      "  1728.5928  1739.7432  1747.4581  1753.4513  1764.4181  1767.5985\n",
      "  1774.8297  1779.5592  1791.3201  1801.45    1820.1228  1829.3396\n",
      "  1852.0891  1857.4203  1869.8115  1872.7921  1888.1279  1897.2958\n",
      "  1901.9084  1919.2925  1937.5717  1962.1475  1974.0154  1992.7412\n",
      "  2009.3231  2015.6682  2030.4316  2040.8151  2057.2395  2065.5242\n",
      "  2087.2117  2107.014   2156.35    2172.52    2176.8215  2187.4546\n",
      "  2212.1738  2228.735   2257.575   2289.8752  2301.2908  2332.2092\n",
      "  2352.8594  2363.6982  2379.0508  2385.1843  2418.6836  2442.285\n",
      "  2464.5476  2487.109   2516.0276  2571.4434  2592.0396  2612.5588\n",
      "  2629.3323  2657.8743  2702.2285  2725.815   2802.9348  2828.4136\n",
      "  2877.224   2928.0918  3010.5251  3040.3257  3179.1692  3218.373\n",
      "  3329.0159  3431.9404  3492.94    3641.9866  3899.2532  3951.5496\n",
      "  4048.7095  4386.202   4441.531   4806.1636  4874.166   5432.0356\n",
      "  6040.7075  6212.678   8965.205  22796.08   64333.16  ]\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(sq_likesMAT_1_evals)[8900:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "498d732f-55bc-4254-9560-e25c9c199078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9025,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_likesMAT_1_evals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4de455ee-8a46-49ba-8d79-60b82cae1218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8856,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sq_likesMAT_1_evals).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f066434-9786-41ae-bb5b-3d5c8255849a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as pp\n",
    "val = 0. # this is the value where you want the data to appear on the y-axis.\n",
    "pp.plot(np.asarray(range(np.unique(sq_likesMAT_1_evals)[7050:].shape[0])) + val, np.sort(np.unique(sq_likesMAT_1_evals))[7050:], 'x')\n",
    "pp.show()\n",
    "\n",
    "# plt.hist(np.sort(sq_likesMAT_1_evals), bins='auto')  # arguments are passed to np.histogram\n",
    "# plt.title(\"Histogram with 'auto' bins\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01204478-b498-42a7-9fc7-645f8a2e7b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1023.94855"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(sq_likesMAT_1_evals)[8800]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e6def-3067-409f-a9ed-2d404d4f2af1",
   "metadata": {},
   "source": [
    "### Compute to 51 eigenvalues ==> SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc5ef07f-e037-4fe1-be62-73663b4c73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linalg.eig(sq_likesMAT_1.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55f2fd46-4e8b-46e9-9c39-df2c73f0c575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TruncatedSVD(algorithm=&#x27;arpack&#x27;, n_components=51)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;TruncatedSVD<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.TruncatedSVD.html\">?<span>Documentation for TruncatedSVD</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>TruncatedSVD(algorithm=&#x27;arpack&#x27;, n_components=51)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "TruncatedSVD(algorithm='arpack', n_components=51)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "svd = TruncatedSVD(n_components=51, algorithm=\"arpack\")\n",
    "svd.fit(train_likesMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6a10821-c5c3-43af-acbf-3b9d697aa549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9025, 51)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_likesMAT = svd.transform(train_likesMAT)\n",
    "svd_likesMAT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa15556-4beb-4c0c-b53c-250a4398dfbb",
   "metadata": {},
   "source": [
    "Delete below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dff47aac-9a38-4802-9c1e-946beaaec62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536204, 536204)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_likesMAT_2 = np.dot(train_likesMAT.T, train_likesMAT)\n",
    "sq_likesMAT_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4249d68b-82bc-4bf5-b14b-7a5ea2eacc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "sq_likesMAT_2_evals = eigs(sq_likesMAT_2, k=1000, return_eigenvectors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "229be6cb-01a9-40db-9366-ac7dd2baf866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  550.16463083+0.j   550.75036953+0.j   550.9088335 +0.j\n",
      "   551.77100993+0.j   552.04466479+0.j   552.65734188+0.j\n",
      "   553.67105667+0.j   554.54485058+0.j   555.20333537+0.j\n",
      "   555.63676949+0.j   556.5089066 +0.j   556.6935497 +0.j\n",
      "   557.15592212+0.j   558.52975936+0.j   559.25504509+0.j\n",
      "   559.50712806+0.j   560.50021344+0.j   561.06460021+0.j\n",
      "   561.13831631+0.j   562.13177508+0.j   562.25893121+0.j\n",
      "   562.73863432+0.j   563.71456712+0.j   565.75783871+0.j\n",
      "   566.45589786+0.j   566.97490319+0.j   567.41140167+0.j\n",
      "   567.8227869 +0.j   569.19212299+0.j   569.90948298+0.j\n",
      "   570.12903664+0.j   570.77579746+0.j   571.55168931+0.j\n",
      "   573.04768706+0.j   573.58288375+0.j   574.21845921+0.j\n",
      "   574.67669768+0.j   575.77970428+0.j   576.63056399+0.j\n",
      "   577.28388682+0.j   577.66760536+0.j   578.35884138+0.j\n",
      "   579.15813845+0.j   580.28574608+0.j   581.91175447+0.j\n",
      "   581.99668265+0.j   583.00438155+0.j   583.6741155 +0.j\n",
      "   584.41668559+0.j   585.00482556+0.j   585.18586476+0.j\n",
      "   586.20862676+0.j   586.65462081+0.j   587.33000344+0.j\n",
      "   588.45341241+0.j   589.11059687+0.j   589.81709753+0.j\n",
      "   589.88559346+0.j   591.59497005+0.j   592.17099184+0.j\n",
      "   592.94329303+0.j   593.67032836+0.j   594.53396202+0.j\n",
      "   595.59434041+0.j   595.84248487+0.j   596.48128262+0.j\n",
      "   597.70530765+0.j   597.95799715+0.j   598.97345337+0.j\n",
      "   599.71913049+0.j   600.3098934 +0.j   602.31777635+0.j\n",
      "   603.67165953+0.j   604.30095359+0.j   605.07960101+0.j\n",
      "   605.34927647+0.j   606.60038795+0.j   607.12905768+0.j\n",
      "   607.40317443+0.j   607.90836302+0.j   609.57984665+0.j\n",
      "   610.2655356 +0.j   610.60091217+0.j   611.82342576+0.j\n",
      "   612.23020721+0.j   613.05156792+0.j   613.50614291+0.j\n",
      "   614.53177899+0.j   615.65997218+0.j   615.98009282+0.j\n",
      "   617.04548209+0.j   617.72662896+0.j   618.85777522+0.j\n",
      "   619.22258304+0.j   620.25636328+0.j   621.89419308+0.j\n",
      "   622.78432949+0.j   623.25370013+0.j   624.15733289+0.j\n",
      "   624.86677481+0.j   626.5256442 +0.j   626.78052205+0.j\n",
      "   627.46662111+0.j   628.06006492+0.j   629.8141303 +0.j\n",
      "   630.0226846 +0.j   630.43343151+0.j   631.71619681+0.j\n",
      "   632.36739332+0.j   633.38369196+0.j   634.02928774+0.j\n",
      "   634.78656553+0.j   634.96963336+0.j   637.08915257+0.j\n",
      "   637.17362544+0.j   637.40476626+0.j   638.41037655+0.j\n",
      "   639.20723406+0.j   639.55824014+0.j   640.57275779+0.j\n",
      "   642.66188201+0.j   644.28424942+0.j   644.76885624+0.j\n",
      "   645.47587622+0.j   645.99991336+0.j   646.87033084+0.j\n",
      "   648.28726805+0.j   649.32316819+0.j   650.49038822+0.j\n",
      "   650.60454279+0.j   651.17617351+0.j   653.38854281+0.j\n",
      "   653.55218312+0.j   654.37759427+0.j   656.23986781+0.j\n",
      "   657.10942697+0.j   657.97930013+0.j   658.46020923+0.j\n",
      "   659.41862881+0.j   659.8903739 +0.j   661.21105443+0.j\n",
      "   661.99767243+0.j   663.11641987+0.j   664.93291315+0.j\n",
      "   665.25250917+0.j   666.43660141+0.j   666.65045433+0.j\n",
      "   668.75790273+0.j   670.71424585+0.j   670.90869228+0.j\n",
      "   671.80408725+0.j   672.86708063+0.j   674.52382491+0.j\n",
      "   675.38124369+0.j   675.67378856+0.j   676.75866108+0.j\n",
      "   677.37756863+0.j   678.66393981+0.j   679.2620711 +0.j\n",
      "   681.44206472+0.j   681.96080865+0.j   683.45822583+0.j\n",
      "   684.39482083+0.j   685.48475719+0.j   685.64461174+0.j\n",
      "   687.45117945+0.j   688.182655  +0.j   690.71789658+0.j\n",
      "   691.35796015+0.j   691.70245167+0.j   693.78256443+0.j\n",
      "   694.43920177+0.j   695.50857833+0.j   696.61710077+0.j\n",
      "   698.29643582+0.j   698.77065151+0.j   700.22031766+0.j\n",
      "   700.30821793+0.j   702.54760654+0.j   703.12409852+0.j\n",
      "   703.40828613+0.j   704.24041211+0.j   705.18630642+0.j\n",
      "   706.86171492+0.j   708.33487851+0.j   710.37416547+0.j\n",
      "   711.07735877+0.j   712.32752637+0.j   712.72259788+0.j\n",
      "   713.21717846+0.j   714.90485864+0.j   716.91021363+0.j\n",
      "   717.69599425+0.j   718.95101895+0.j   720.06528417+0.j\n",
      "   721.69560446+0.j   722.19990812+0.j   723.57738069+0.j\n",
      "   725.35462346+0.j   726.60532487+0.j   727.03773565+0.j\n",
      "   727.44939277+0.j   729.52097806+0.j   730.49729599+0.j\n",
      "   731.09980688+0.j   733.05082979+0.j   734.17505681+0.j\n",
      "   735.00010554+0.j   735.68700374+0.j   736.82816045+0.j\n",
      "   737.08336162+0.j   738.87526589+0.j   741.56887685+0.j\n",
      "   741.72219463+0.j   742.65377277+0.j   744.01369984+0.j\n",
      "   746.17407202+0.j   747.53585246+0.j   748.80034944+0.j\n",
      "   750.46854319+0.j   751.07486769+0.j   753.35363714+0.j\n",
      "   753.80211525+0.j   755.88818837+0.j   756.8547821 +0.j\n",
      "   759.13211719+0.j   760.21850281+0.j   760.47128298+0.j\n",
      "   762.71815389+0.j   764.54555681+0.j   765.91152269+0.j\n",
      "   766.30371835+0.j   768.30974679+0.j   769.51998427+0.j\n",
      "   770.51552243+0.j   772.404398  +0.j   773.17590441+0.j\n",
      "   773.64444193+0.j   775.43632837+0.j   775.81199174+0.j\n",
      "   778.6391402 +0.j   778.90681064+0.j   780.76864003+0.j\n",
      "   782.64855304+0.j   783.48682763+0.j   785.41499144+0.j\n",
      "   787.10299426+0.j   787.49583722+0.j   789.77502158+0.j\n",
      "   791.38607533+0.j   792.37130554+0.j   793.29292703+0.j\n",
      "   795.61264891+0.j   796.46324363+0.j   797.89145165+0.j\n",
      "   799.74507623+0.j   800.7701531 +0.j   801.32260244+0.j\n",
      "   802.48722077+0.j   803.73962475+0.j   806.0917479 +0.j\n",
      "   808.07637213+0.j   810.68500752+0.j   811.1306567 +0.j\n",
      "   812.04097213+0.j   813.2458398 +0.j   814.13074328+0.j\n",
      "   816.85149754+0.j   818.21506433+0.j   820.19944253+0.j\n",
      "   820.84003701+0.j   821.82765761+0.j   824.54164707+0.j\n",
      "   825.6737435 +0.j   828.10044398+0.j   829.58273313+0.j\n",
      "   830.5127187 +0.j   833.08608618+0.j   833.79494785+0.j\n",
      "   834.60493384+0.j   836.30103669+0.j   837.34119066+0.j\n",
      "   839.90255418+0.j   840.55310993+0.j   842.86347683+0.j\n",
      "   844.0989012 +0.j   845.9224151 +0.j   847.93039551+0.j\n",
      "   849.49728572+0.j   853.10744191+0.j   853.18140911+0.j\n",
      "   854.36563708+0.j   855.1242648 +0.j   856.94825912+0.j\n",
      "   859.74692385+0.j   861.77946433+0.j   863.8243208 +0.j\n",
      "   866.20363942+0.j   866.65398781+0.j   867.94796888+0.j\n",
      "   870.05993057+0.j   871.71453904+0.j   873.34368657+0.j\n",
      "   875.48580656+0.j   876.2461836 +0.j   877.88795785+0.j\n",
      "   878.90739716+0.j   879.23604267+0.j   882.2258785 +0.j\n",
      "   883.13896535+0.j   883.50001603+0.j   886.70772353+0.j\n",
      "   889.8879434 +0.j   890.75793623+0.j   892.44601587+0.j\n",
      "   894.84197155+0.j   899.31720034+0.j   899.69088029+0.j\n",
      "   902.17314933+0.j   903.51964968+0.j   904.49821338+0.j\n",
      "   905.60667583+0.j   906.8650255 +0.j   909.28064941+0.j\n",
      "   911.49983574+0.j   912.08005599+0.j   914.34648572+0.j\n",
      "   916.97125538+0.j   919.67254296+0.j   921.62167679+0.j\n",
      "   923.89362332+0.j   925.73868624+0.j   927.5044911 +0.j\n",
      "   928.85641031+0.j   929.85749738+0.j   932.80719543+0.j\n",
      "   934.12736219+0.j   935.93782685+0.j   937.89386062+0.j\n",
      "   938.70391378+0.j   939.9502596 +0.j   941.98084763+0.j\n",
      "   946.4582292 +0.j   948.22135946+0.j   951.95590506+0.j\n",
      "   952.92334121+0.j   954.38722301+0.j   957.7389132 +0.j\n",
      "   960.04157318+0.j   962.88915059+0.j   963.26652131+0.j\n",
      "   964.72204155+0.j   966.59371138+0.j   970.93195987+0.j\n",
      "   973.78969099+0.j   978.91984266+0.j   979.73803858+0.j\n",
      "   982.9356982 +0.j   985.88141184+0.j   986.8723612 +0.j\n",
      "   989.58527167+0.j   992.04101009+0.j   994.13763309+0.j\n",
      "   994.80420553+0.j  1000.62699101+0.j  1002.2835788 +0.j\n",
      "  1004.01683079+0.j  1005.30658116+0.j  1006.35463123+0.j\n",
      "  1007.6589929 +0.j  1011.15179607+0.j  1012.56613349+0.j\n",
      "  1016.46497757+0.j  1018.63269294+0.j  1019.4506173 +0.j\n",
      "  1023.95115727+0.j  1025.66136757+0.j  1029.08630557+0.j\n",
      "  1030.02097019+0.j  1032.37370342+0.j  1033.11059127+0.j\n",
      "  1041.29924547+0.j  1041.51319875+0.j  1043.80151775+0.j\n",
      "  1046.08833448+0.j  1048.65455621+0.j  1050.90722145+0.j\n",
      "  1052.1343446 +0.j  1054.17692561+0.j  1058.29330046+0.j\n",
      "  1061.10624851+0.j  1063.69613784+0.j  1065.66990808+0.j\n",
      "  1071.87120041+0.j  1073.8894782 +0.j  1077.32646898+0.j\n",
      "  1080.79847907+0.j  1084.46841345+0.j  1088.76555763+0.j\n",
      "  1090.47096445+0.j  1092.21171737+0.j  1095.77327587+0.j\n",
      "  1099.84037756+0.j  1101.06873057+0.j  1101.74871843+0.j\n",
      "  1105.64891049+0.j  1111.90731483+0.j  1115.18273092+0.j\n",
      "  1119.55135973+0.j  1122.44739126+0.j  1127.11660377+0.j\n",
      "  1133.06745384+0.j  1135.91602194+0.j  1138.48891395+0.j\n",
      "  1142.00578792+0.j  1147.85382688+0.j  1153.95774867+0.j\n",
      "  1157.20839035+0.j  1157.95240329+0.j  1161.94508455+0.j\n",
      "  1163.410759  +0.j  1171.42500593+0.j  1172.89689085+0.j\n",
      "  1175.53329993+0.j  1178.60392775+0.j  1183.0431938 +0.j\n",
      "  1189.92237034+0.j  1194.60909499+0.j  1198.8827916 +0.j\n",
      "  1201.5473628 +0.j  1205.87015536+0.j  1212.93362926+0.j\n",
      "  1215.54023728+0.j  1219.60933303+0.j  1222.5745383 +0.j\n",
      "  1226.56744753+0.j  1230.83932197+0.j  1237.06578774+0.j\n",
      "  1240.25434253+0.j  1242.49808222+0.j  1253.14082038+0.j\n",
      "  1256.25353708+0.j  1260.19655406+0.j  1262.29785124+0.j\n",
      "  1266.19898326+0.j  1266.9113962 +0.j  1269.65536366+0.j\n",
      "  1278.15476011+0.j  1284.19600251+0.j  1288.28813266+0.j\n",
      "  1294.09584412+0.j  1296.64662151+0.j  1298.18405019+0.j\n",
      "  1307.92882111+0.j  1311.67838069+0.j  1316.00126638+0.j\n",
      "  1319.31256731+0.j  1327.3777859 +0.j  1332.62640834+0.j\n",
      "  1338.57192853+0.j  1342.70863898+0.j  1349.42443418+0.j\n",
      "  1353.99621229+0.j  1358.45202943+0.j  1366.69439327+0.j\n",
      "  1369.21981868+0.j  1370.85306532+0.j  1377.99459576+0.j\n",
      "  1380.55836798+0.j  1388.31679255+0.j  1396.36355355+0.j\n",
      "  1398.40490374+0.j  1399.87689475+0.j  1416.70897261+0.j\n",
      "  1419.71982211+0.j  1424.17060984+0.j  1436.38634956+0.j\n",
      "  1437.71221058+0.j  1440.22255071+0.j  1441.64203497+0.j\n",
      "  1448.30899113+0.j  1454.6929209 +0.j  1464.52586875+0.j\n",
      "  1469.14576641+0.j  1474.53751808+0.j  1481.43685996+0.j\n",
      "  1487.34818667+0.j  1493.58482353+0.j  1499.35400339+0.j\n",
      "  1508.52463883+0.j  1514.27201284+0.j  1521.73968122+0.j\n",
      "  1529.09520976+0.j  1537.62217627+0.j  1544.01066701+0.j\n",
      "  1545.98454175+0.j  1561.23235921+0.j  1575.58301321+0.j\n",
      "  1578.52152463+0.j  1580.85247641+0.j  1584.54969822+0.j\n",
      "  1593.22400829+0.j  1598.57592969+0.j  1613.5688739 +0.j\n",
      "  1614.3947076 +0.j  1623.53614304+0.j  1642.3964229 +0.j\n",
      "  1648.14214109+0.j  1653.861561  +0.j  1671.4509191 +0.j\n",
      "  1677.49496067+0.j  1683.72389186+0.j  1687.94342699+0.j\n",
      "  1699.48399601+0.j  1708.36192405+0.j  1715.93520852+0.j\n",
      "  1721.64750755+0.j  1728.53675836+0.j  1739.71238345+0.j\n",
      "  1747.39867477+0.j  1753.41530158+0.j  1764.36846953+0.j\n",
      "  1767.52366313+0.j  1774.78928461+0.j  1779.49441672+0.j\n",
      "  1791.28997173+0.j  1801.43121965+0.j  1820.10440721+0.j\n",
      "  1829.30746454+0.j  1852.04211664+0.j  1857.39686485+0.j\n",
      "  1869.74209451+0.j  1872.72134534+0.j  1888.09822785+0.j\n",
      "  1897.27078701+0.j  1901.86292637+0.j  1919.2711473 +0.j\n",
      "  1937.54687971+0.j  1962.12946511+0.j  1973.97453447+0.j\n",
      "  1992.69694693+0.j  2009.27839004+0.j  2015.63957949+0.j\n",
      "  2030.39983783+0.j  2040.78699374+0.j  2057.23231871+0.j\n",
      "  2065.52031034+0.j  2087.20830482+0.j  2107.01170158+0.j\n",
      "  2156.31714487+0.j  2172.4766741 +0.j  2176.77443061+0.j\n",
      "  2187.4122549 +0.j  2212.15475184+0.j  2228.71878984+0.j\n",
      "  2257.55588147+0.j  2289.85328532+0.j  2301.25099742+0.j\n",
      "  2332.18825353+0.j  2352.82903226+0.j  2363.65623644+0.j\n",
      "  2379.02213552+0.j  2385.14826845+0.j  2418.6678995 +0.j\n",
      "  2442.26572298+0.j  2464.52645373+0.j  2487.08747007+0.j\n",
      "  2516.0055374 +0.j  2571.42941643+0.j  2592.00233843+0.j\n",
      "  2612.53228015+0.j  2629.3098873 +0.j  2657.83112569+0.j\n",
      "  2702.2152484 +0.j  2725.78370908+0.j  2802.92119759+0.j\n",
      "  2828.3661046 +0.j  2877.20028825+0.j  2928.0576003 +0.j\n",
      "  3010.5106422 +0.j  3040.28111693+0.j  3179.1548518 +0.j\n",
      "  3218.33079451+0.j  3329.00250213+0.j  3431.93341548+0.j\n",
      "  3492.91697702+0.j  3641.95943013+0.j  3899.24746964+0.j\n",
      "  3951.51406688+0.j  4048.68452432+0.j  4386.18475959+0.j\n",
      "  4441.4945183 +0.j  4806.12453947+0.j  4874.13965725+0.j\n",
      "  5432.01419805+0.j  6040.67355348+0.j  6212.64162559+0.j\n",
      "  8965.15677368+0.j 22796.01936173+0.j 64332.88357166+0.j]\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(sq_likesMAT_2_evals)[400:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2407e-2461-443b-a52b-fc7cda6ab95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_likesMAT_2_evals = linalg.eig(sq_likesMAT_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a006f814-38c1-48d5-b497-927ac4464882",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.74 GiB. GPU 0 has a total capacity of 3.81 GiB of which 3.69 GiB is free. Including non-PyTorch memory, this process has 114.00 MiB memory in use. Of the allocated memory 29.19 MiB is allocated by PyTorch, and 16.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDataset\n\u001b[1;32m      3\u001b[0m tensor_likesMAT \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(likesMAT\u001b[38;5;241m.\u001b[39mtodense())\u001b[38;5;66;03m#.to_sparse()\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tensor_likesMAT \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_likesMAT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat8_e4m3fn\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m tensor_likesMAT\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.74 GiB. GPU 0 has a total capacity of 3.81 GiB of which 3.69 GiB is free. Including non-PyTorch memory, this process has 114.00 MiB memory in use. Of the allocated memory 29.19 MiB is allocated by PyTorch, and 16.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "tensor_likesMAT = torch.Tensor(likesMAT.todense())#.to_sparse()\n",
    "tensor_likesMAT = tensor_likesMAT.to(torch.float8_e4m3fn).cuda()\n",
    "\n",
    "tensor_likesMAT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2371d6d-210e-4d41-b9f4-6dab6b5d8118",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::_linalg_svd' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_linalg_svd' is only available for these backends: [CPU, CUDA, HIP, MPS, IPU, XPU, HPU, VE, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nUndefined: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:30455 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:44681 [kernel]\nHIP: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMPS: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nIPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nXPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nHPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nVE: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMTIA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nPrivateUse1: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nPrivateUse2: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nPrivateUse3: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMeta: registered at /dev/null:241 [kernel]\nFPGA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMAIA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nVulkan: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMetal: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedHIP: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedMPS: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedIPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedXPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedHPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedVE: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedMTIA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedPrivateUse1: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedPrivateUse2: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedPrivateUse3: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedMeta: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nCustomRNGKeyId: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMkldnnCPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrCPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrCUDA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrHIP: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrMPS: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrIPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrXPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrHPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrVE: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrMTIA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrPrivateUse1: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrPrivateUse2: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrPrivateUse3: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrMeta: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_4.cpp:13374 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/BatchRulesLinearAlgebra.cpp:593 [kernel]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_likesMAT\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::_linalg_svd' with arguments from the 'SparseCUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_linalg_svd' is only available for these backends: [CPU, CUDA, HIP, MPS, IPU, XPU, HPU, VE, MTIA, PrivateUse1, PrivateUse2, PrivateUse3, Meta, FPGA, MAIA, Vulkan, Metal, QuantizedCPU, QuantizedCUDA, QuantizedHIP, QuantizedMPS, QuantizedIPU, QuantizedXPU, QuantizedHPU, QuantizedVE, QuantizedMTIA, QuantizedPrivateUse1, QuantizedPrivateUse2, QuantizedPrivateUse3, QuantizedMeta, CustomRNGKeyId, MkldnnCPU, SparseCsrCPU, SparseCsrCUDA, SparseCsrHIP, SparseCsrMPS, SparseCsrIPU, SparseCsrXPU, SparseCsrHPU, SparseCsrVE, SparseCsrMTIA, SparseCsrPrivateUse1, SparseCsrPrivateUse2, SparseCsrPrivateUse3, SparseCsrMeta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradMeta, AutogradNestedTensor, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nUndefined: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:30455 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:44681 [kernel]\nHIP: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMPS: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nIPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nXPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nHPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nVE: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMTIA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nPrivateUse1: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nPrivateUse2: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nPrivateUse3: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMeta: registered at /dev/null:241 [kernel]\nFPGA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMAIA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nVulkan: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMetal: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedCPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedCUDA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedHIP: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedMPS: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedIPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedXPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedHPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedVE: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedMTIA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedPrivateUse1: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedPrivateUse2: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedPrivateUse3: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nQuantizedMeta: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nCustomRNGKeyId: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nMkldnnCPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrCPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrCUDA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrHIP: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrMPS: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrIPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrXPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrHPU: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrVE: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrMTIA: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrPrivateUse1: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrPrivateUse2: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrPrivateUse3: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nSparseCsrMeta: registered at aten/src/ATen/RegisterCompositeExplicitAutogradNonFunctional.cpp:21612 [default backend kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_4.cpp:18531 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_4.cpp:13374 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/BatchRulesLinearAlgebra.cpp:593 [kernel]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "torch.linalg.cond(tensor_likesMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1538b3e4-567c-42d3-8287-bcf537e64c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "tensor_likesMAT = torch.Tensor(likesMAT.todense()).to_sparse()\n",
    "tensor_likesMAT = tensor_likesMAT.to(torch.bfloat16).cuda()\n",
    "\n",
    "tensor_agesARR = torch.Tensor(agesARR)\n",
    "tensor_agesARR = tensor_agesARR.to(torch.bool).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb0f769c-1dd7-49a5-97eb-a024bca61294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# tensor_likesMAT = torch.Tensor(likesMAT.todense())#.to_sparse()\n",
    "# tensor_likesMAT = tensor_likesMAT.to(torch.float8_e4m3fn)\n",
    "# tensor_likesMAT = tensor_likesMAT.cuda()\n",
    "# tensor_agesARR = torch.Tensor(agesARR)\n",
    "# tensor_agesARR = tensor_agesARR.to(torch.bool)\n",
    "# tensor_agesARR = tensor_agesARR.cuda()\n",
    "\n",
    "tensor_train_likesMAT = torch.Tensor(train_likesMAT.todense())#.to_sparse()\n",
    "tensor_train_likesMAT = tensor_train_likesMAT.to(torch.torch.bfloat16)#.cuda()\n",
    "tensor_test_likesMAT = torch.Tensor(test_likesMAT.todense())#.to_sparse()\n",
    "tensor_test_likesMAT = tensor_test_likesMAT.to(torch.torch.bfloat16)\n",
    "\n",
    "tensor_train_agesARR = torch.Tensor(train_agesARR)\n",
    "tensor_train_agesARR = tensor_train_agesARR.to(torch.torch.bfloat16)#.cuda()\n",
    "tensor_test_agesARR = torch.Tensor(test_agesARR)\n",
    "tensor_test_agesARR = tensor_test_agesARR.to(torch.torch.bfloat16)\n",
    "\n",
    "# tensor_dataset = TensorDataset(tensor_likesMAT, tensor_agesARR)\n",
    "# tensor_loader = DataLoader(tensor_dataset, batch_size=128)\n",
    "# tensor_loader = DataLoader(tensor_dataset, batch_size=9500)\n",
    "\n",
    "tensor_train_dataset = TensorDataset(tensor_train_likesMAT, tensor_train_agesARR)\n",
    "tensor_train_loader = DataLoader(tensor_train_dataset, batch_size=32)\n",
    "\n",
    "tensor_test_dataset = TensorDataset(tensor_test_likesMAT, tensor_test_agesARR)\n",
    "tensor_test_loader = DataLoader(tensor_test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33668ec9-7581-4ecd-bc06-34944ad883dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2afa01c4-d207-4f3f-927f-f99f36d96d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as t_func\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(536204, 1125)\n",
    "        self.drop1 = nn.Dropout(p=0.25)\n",
    "        self.fc2 = nn.Linear(1125, 1500).to(device)\n",
    "        self.drop2 = nn.Dropout(p=0.375).to(device)\n",
    "        self.fc3 = nn.Linear(1500, 1125).to(device)\n",
    "        self.drop3 = nn.Dropout(p=0.25).to(device)\n",
    "        self.fc4 = nn.Linear(1125, 750).to(device)\n",
    "        self.fc5 = nn.Linear(750, 4).to(device)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = t_func.relu(x)\n",
    "        x = self.drop1(x)\n",
    "        x = x.to(device)\n",
    "        x = self.fc2(x)\n",
    "        sm = nn.Softmax(dim=1)\n",
    "        # x = t_func.log_softmax(x)\n",
    "        x = sm(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = t_func.sigmoid(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = t_func.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = sm(x)\n",
    "        # x = t_func.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e18c9b-d293-455b-b788-6a0c5e5b7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "network = Net()\n",
    "network = network.to(torch.bfloat16)#.cuda()\n",
    "optimizer = optim.Adam(network.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 10\n",
    "losses = []\n",
    "counter = []\n",
    "\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tensor_train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs#.cuda()\n",
    "        labels = labels#.cuda()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = network(inputs)\n",
    "        # outputs = outputs.cuda()\n",
    "        loss = criterion(outputs.to(torch.device(\"cpu\")), labels.to(torch.device(\"cpu\")))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5570ab-087a-4152-8864-47d5c9a71eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c5dfdee-96bc-4181-8f91-7c5b20abb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "network = Net()\n",
    "network = network.to(torch.bfloat16)#.cuda()\n",
    "optimizer = optim.Adam(network.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 10\n",
    "losses = []\n",
    "counter = []\n",
    "\n",
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_ind, (data, target) in enumerate(tensor_loader):\n",
    "        data = data.unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_ind % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_ind * len(data), len(tensor_loader.dataset), \n",
    "                100.0 * batch_ind / len(tensor_loader), loss.item()))\n",
    "            losses.append(loss.item())\n",
    "            counter.append((batch_ind*64) + ((epoch-1)*len(tensor_loader.dataset)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e073589-12c6-4b51-b8e9-a57b80cd5a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs+1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f58c4d7-5cf7-4a26-93ae-a84dfa75eef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-07-29 18:09:35.214514: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-29 18:09:35.400420: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 18:09:35.490235: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 18:09:35.511864: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 18:09:35.674471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_8823/1630248790.py\", line 26, in <module>\n",
      "    model.fit(likesMAT, agesARR, epochs=10)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py\", line 118, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/backend/torch/trainer.py\", line 241, in fit\n",
      "    epoch_iterator = EpochIterator(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/trainers/epoch_iterator.py\", line 79, in __init__\n",
      "    elif tf.available and isinstance(x, tf.data.Dataset):\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/module_utils.py\", line 16, in available\n",
      "    self.initialize()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/module_utils.py\", line 24, in initialize\n",
      "    self.module = importlib.import_module(self.name)\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 46, in <module>\n",
      "    from tensorflow.python import pywrap_tfe\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/pywrap_tfe.py\", line 25, in <module>\n",
      "    from tensorflow.python._pywrap_tfe import *\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_8823/1630248790.py\", line 26, in <module>\n",
      "    model.fit(likesMAT, agesARR, epochs=10)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py\", line 118, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/backend/torch/trainer.py\", line 241, in fit\n",
      "    epoch_iterator = EpochIterator(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/trainers/epoch_iterator.py\", line 79, in __init__\n",
      "    elif tf.available and isinstance(x, tf.data.Dataset):\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/module_utils.py\", line 16, in available\n",
      "    self.initialize()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/module_utils.py\", line 24, in initialize\n",
      "    self.module = importlib.import_module(self.name)\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 49, in <module>\n",
      "    from tensorflow.python.client import pywrap_tf_session\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/client/pywrap_tf_session.py\", line 19, in <module>\n",
      "    from tensorflow.python.client._pywrap_tf_session import *\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_8823/1630248790.py\", line 26, in <module>\n",
      "    model.fit(likesMAT, agesARR, epochs=10)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py\", line 118, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/backend/torch/trainer.py\", line 241, in fit\n",
      "    epoch_iterator = EpochIterator(\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/trainers/epoch_iterator.py\", line 79, in __init__\n",
      "    elif tf.available and isinstance(x, tf.data.Dataset):\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/module_utils.py\", line 16, in available\n",
      "    self.initialize()\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/module_utils.py\", line 24, in initialize\n",
      "    self.module = importlib.import_module(self.name)\n",
      "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 11, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import distribute\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__.distribute import combinations\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.distribute.combinations import env # line: 456\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/distribute/combinations.py\", line 33, in <module>\n",
      "    from tensorflow.python.distribute import collective_all_reduce_strategy\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py\", line 25, in <module>\n",
      "    from tensorflow.python.distribute import cross_device_ops as cross_device_ops_lib\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/distribute/cross_device_ops.py\", line 28, in <module>\n",
      "    from tensorflow.python.distribute import cross_device_utils\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/distribute/cross_device_utils.py\", line 22, in <module>\n",
      "    from tensorflow.python.distribute import values as value_lib\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/distribute/values.py\", line 23, in <module>\n",
      "    from tensorflow.python.distribute import distribute_lib\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 205, in <module>\n",
      "    from tensorflow.python.data.ops import dataset_ops\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/data/__init__.py\", line 21, in <module>\n",
      "    from tensorflow.python.data import experimental\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/data/experimental/__init__.py\", line 98, in <module>\n",
      "    from tensorflow.python.data.experimental import service\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/data/experimental/service/__init__.py\", line 419, in <module>\n",
      "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\", line 26, in <module>\n",
      "    from tensorflow.python.data.ops import dataset_ops\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 34, in <module>\n",
      "    from tensorflow.python.data.ops import iterator_ops\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 45, in <module>\n",
      "    from tensorflow.python.training.saver import BaseSaverBuilder\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/training/saver.py\", line 50, in <module>\n",
      "    from tensorflow.python.training import py_checkpoint_reader\n",
      "  File \"/home/jamster/keras_torch/lib/python3.11/site-packages/tensorflow/python/training/py_checkpoint_reader.py\", line 19, in <module>\n",
      "    from tensorflow.python.util._pywrap_checkpoint_reader import CheckpointReader\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "initialization of _pywrap_checkpoint_reader raised unreported exception",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 26\u001b[0m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m4\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m \t\t\t\tloss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     24\u001b[0m \t\t\t\tmetrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlikesMAT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magesARR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/keras_torch/lib/python3.11/site-packages/keras_core/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras_core.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1149\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/keras_torch/lib/python3.11/site-packages/tensorflow/__init__.py:47\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     45\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m~/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[0;32m~/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/distribute/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[0;32m~/keras_torch/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/distribute/combinations/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "\u001b[0;31mSystemError\u001b[0m: initialization of _pywrap_checkpoint_reader raised unreported exception"
     ]
    }
   ],
   "source": [
    "# Training Model\n",
    "###############\n",
    "print(\"start training\")\n",
    "\n",
    "numInputs = 750 # Number of nodes to map inputs\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(int(numInputs*1.5),\n",
    "\t\t\t\tinput_dim=int(likesMAT.shape[1]),\n",
    "\t\t\t\tactivation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense((numInputs*2),\n",
    "\t\t\t\tactivation='softmax'))\n",
    "model.add(Dropout(0.375))\n",
    "model.add(Dense(int(numInputs*1.5),\n",
    "\t\t\t\tactivation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(numInputs,\n",
    "\t\t\t\tactivation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "\t\t\t\tloss='categorical_crossentropy',\n",
    "\t\t\t\tmetrics=['accuracy', 'mse'])\n",
    "\n",
    "model.fit(likesMAT, agesARR, epochs=10)\n",
    "\n",
    "print(\"end training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316420c-eaa3-4421-ac15-525bea899750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_torch",
   "language": "python",
   "name": "keras_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
